{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "630b4dd3-42ae-4546-9bb9-d83cb9aa9684",
   "metadata": {},
   "source": [
    "# Mental imagery\n",
    "\n",
    "This notebook provides loading functions and is a basic analysis pipeline for mental imagery recordings.\n",
    "\n",
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0e3c00-3ef2-46fb-b29b-d1740e916359",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from itertools import chain\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pyxdf\n",
    "import mne\n",
    "from mne.decoding import CSP\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import (\n",
    "    KFold,\n",
    "    LeaveOneGroupOut,\n",
    "    LeavePGroupsOut,\n",
    "    cross_val_score,\n",
    "    cross_val_predict,\n",
    ")\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed623409-92c0-4bf6-996f-2bdf3dc9ff77",
   "metadata": {},
   "source": [
    "## Loading functions\n",
    "\n",
    "Please refer to the doc-strings of the functions bellow to understand what they are doing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c61849-485b-404a-b979-eaf3ca84b37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some hyper-parameters:\n",
    "\n",
    "root = (\n",
    "    Path(\"~/\").expanduser() / \"Desktop\" / \"imagery_2025\"\n",
    ")  # Change this according to where you saved the data\n",
    "\n",
    "subject = \"VPtest\"\n",
    "session = \"S001\"\n",
    "\n",
    "# blocks with executed movements (see README.md file in the data for more details)\n",
    "blocks_exe = [5, 6, 8]\n",
    "\n",
    "# blocks with imagined movements (see README.md file in the data for more details)\n",
    "blocks_ima = [3, 4, 7]\n",
    "\n",
    "eeg_stream_name = \"BrainVision RDA\"\n",
    "imagery_markers_stream_name = \"ImageryParadigmMarkerStream\"\n",
    "\n",
    "id_event = {\n",
    "    110: \"left_hand\",\n",
    "    111: \"right_hand\",\n",
    "    112: \"feet\",\n",
    "    113: \"mental_arithmetic\",\n",
    "}\n",
    "classes = list(id_event.values())\n",
    "cue_time_s = 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473dfc06-ceff-4153-bfa5-dbd3219abb3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_filepath(\n",
    "    block: int,\n",
    "    task: str,\n",
    "    subject: str = subject,\n",
    "    session: str = session,\n",
    "    root: Path = root,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns the path to a file saved in a BIDS data structure.\n",
    "\n",
    "    for example: sub-VPtest/ses-S001/eegsub-VPtest_ses-S001_task-execution_run-002_eeg.xdf\n",
    "\n",
    "    See https://bids.neuroimaging.io\n",
    "    \"\"\"\n",
    "    return (\n",
    "        root\n",
    "        / f\"sub-{subject}\"\n",
    "        / f\"ses-{session}\"\n",
    "        / \"eeg\"\n",
    "        / f\"sub-{subject}_ses-{session}_task-{task}_run-{block:03d}_eeg.xdf\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89ddfd4-bb62-443f-aa29-881cd0ea3b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imagery_xdf_mne(filepath: Path):\n",
    "    \"\"\"\n",
    "    Used to load a `.xdf` file and place it in an `mne.io.Raw` object.\n",
    "    \"\"\"\n",
    "    streams, _ = pyxdf.load_xdf(filepath)\n",
    "    stream_names = [s[\"info\"][\"name\"][0] for s in streams]\n",
    "    eeg_stream = streams[stream_names.index(eeg_stream_name)]\n",
    "    markers_stream = streams[stream_names.index(imagery_markers_stream_name)]\n",
    "    t = eeg_stream[\"time_stamps\"]\n",
    "    sfreq = float(eeg_stream[\"info\"][\"nominal_srate\"][0])\n",
    "\n",
    "    data = eeg_stream[\"time_series\"].T\n",
    "    chans = [\n",
    "        (d[\"label\"][0], d[\"type\"][0].lower())\n",
    "        for d in eeg_stream[\"info\"][\"desc\"][0][\"channels\"][0][\"channel\"]\n",
    "    ]\n",
    "    mask = [t == \"eeg\" for _, t in chans]\n",
    "    chans = [(n, t) for m, (n, t) in zip(mask, chans) if m]\n",
    "    data = data[mask]\n",
    "    ch_names, ch_types = zip(*chans)\n",
    "\n",
    "    info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types)\n",
    "    dirname = filepath.parent.name.split(\"_\")\n",
    "    # info['subject_info'] = dict(\n",
    "    #     his_id=dirname[0],\n",
    "    # )\n",
    "    # info['meas_date'] = datetime.fromisoformat('20'+'-'.join(dirname[1:])+'T00:00:00Z')\n",
    "\n",
    "    raw = mne.io.RawArray(data, info)\n",
    "    markers_time = markers_stream[\"time_stamps\"]\n",
    "    markers = markers_stream[\"time_series\"].flatten()\n",
    "    mask = np.isin(markers, list(id_event.keys()))\n",
    "\n",
    "    annotations = mne.Annotations(\n",
    "        onset=markers_time[mask] - t[0],\n",
    "        duration=cue_time_s,\n",
    "        description=np.vectorize(id_event.get)(markers[mask]),\n",
    "    )\n",
    "    raw.set_annotations(annotations)\n",
    "    return raw\n",
    "\n",
    "\n",
    "def get_epochs(raw):\n",
    "    \"\"\"\n",
    "    Takes an `mne.io.Raw` object as input\n",
    "    and split it into epochs according to it's `annotations` attribute.\n",
    "    Returns an `mne.Epochs` object.\n",
    "    \"\"\"\n",
    "    events, event_id = mne.events_from_annotations(\n",
    "        raw, event_id={v: k for k, v in id_event.items()}\n",
    "    )\n",
    "    epochs = mne.Epochs(raw, events, event_id, tmin=0, tmax=cue_time_s, baseline=None)\n",
    "    return epochs\n",
    "\n",
    "\n",
    "def get_X_y(fnames, fmin=1, fmax=40, resample=128, get_fname=False):\n",
    "    \"\"\"\n",
    "    Takes a list of `.xdf` file paths as input,\n",
    "    loads them into an mne format with `load_imagery_xdf_mne`,\n",
    "    pre-processes them according to the parameters given,\n",
    "    splits them into epochs with `get_epochs`,\n",
    "    and returns concatenated numpy arrays.\n",
    "    \"\"\"\n",
    "    X_list, y_list = [], []\n",
    "    for fname in fnames:\n",
    "        raw = load_imagery_xdf_mne(fname)\n",
    "        raw = raw.filter(fmin, fmax).resample(resample)\n",
    "        epochs = get_epochs(raw)\n",
    "        X_list.append(epochs.get_data())\n",
    "        y_list.append(np.vectorize(id_event.get)(epochs.events[:, 2]))\n",
    "        del raw, epochs\n",
    "    X = np.concatenate(X_list, axis=0)\n",
    "    y = np.concatenate(y_list, axis=0)\n",
    "    if get_fname:\n",
    "        fnames_prod = [\n",
    "            fname for fname, yy in zip(fnames, y_list) for _ in range(len(yy))\n",
    "        ]\n",
    "        return X, y, fnames_prod\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4408c17-1fe2-4bb4-8c73-5e35f6d329c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filenames = {\n",
    "#     block: get_filepath(block, task)\n",
    "#     for task, blocks in zip([\"execution\", \"imagery\"], [blocks_exe, blocks_ima])\n",
    "#     for block in blocks\n",
    "# }\n",
    "\n",
    "# # check the data is correct:\n",
    "# for filename in filenames.values():\n",
    "#         raw = load_imagery_xdf_mne(filename)\n",
    "#         epochs = get_epochs(raw)\n",
    "#         epochs.load_data()\n",
    "#         assert len(epochs) == 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de86b2f6-a489-4310-b85e-fb571146d729",
   "metadata": {},
   "source": [
    "## Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c9b1cd-c067-45e9-90ba-00a7d3403e70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pre-processing parameters:\n",
    "kwargs = dict(\n",
    "    fmin=8,\n",
    "    fmax=12,\n",
    "    resample=40,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e65b98-a8c5-4a57-8e7d-f3de5f06b34a",
   "metadata": {},
   "source": [
    "### Simple train/test split\n",
    "\n",
    "#### load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c92ace-85cd-4894-8cdd-791ab074e8a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_blocks = [3]\n",
    "# test_blocks = [4]\n",
    "\n",
    "# train_X, train_y = get_X_y([filenames[block] for block in train_blocks], **kwargs)\n",
    "# test_X, test_y = get_X_y([filenames[block] for block in train_blocks], **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d29b1be-50f8-44ba-bb5f-ce6fcbaca84b",
   "metadata": {},
   "source": [
    "#### score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c236808-3553-4acc-9294-d0577c2ae462",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clf = make_pipeline(CSP(n_components=8), LogisticRegression())\n",
    "\n",
    "# clf.fit(train_X, train_y)\n",
    "# clf.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d075a62c-d68d-4df6-938b-87fee1a53a07",
   "metadata": {},
   "source": [
    "### Cross-validation\n",
    "\n",
    "#### load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68449b3b-50de-4b11-ab73-01bf0de71822",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select which blocks will be used for cross-validation (see blocks_exe and blocks_ima above):\n",
    "X, y, fnames = get_X_y([filenames[block ]for block in blocks_exe], get_fname=True, **kwargs)\n",
    "# X, y, fnames = get_X_y(list(map(get_filepath, blocks_ima)), get_fname=True, **kwargs)\n",
    "\n",
    "# You can play with the list bellow to only keep certain classes in the data:\n",
    "classes_selected = [\"left_hand\", \"right_hand\", \"feet\", \"mental_arithmetic\"]\n",
    "\n",
    "mask = np.isin(y, classes_selected)\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "fnames = np.array(fnames)[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f28d67-579d-423c-845f-c0cdf503c8c4",
   "metadata": {},
   "source": [
    "#### CV score\n",
    "\n",
    "We use a leave-p-groups-out cross-validation strategy.\n",
    "Here, a group is actually a block.\n",
    "The parameter `n_groups` defines how many blocks will be left out of the training set (and used for testing).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2e136d-d1cc-4698-8ff2-33250138696e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lgo = LeavePGroupsOut(n_groups=1)\n",
    "clf = make_pipeline(CSP(n_components=8), LogisticRegression())\n",
    "\n",
    "score_LeavePGroupsOut = cross_val_score(clf, X, y, groups=fnames, cv=lgo, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274a3890-421b-4591-8081-d203e9be284b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "score_LeavePGroupsOut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c57ff86-3315-4048-9dcb-7951a96e6290",
   "metadata": {},
   "source": [
    "#### confusion matrix\n",
    "\n",
    "We use a leave-one-group-out strategy to compute a prediction for every example in `X`.\n",
    "Then, we display the classification results in a confusion matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef115c5-829c-4ae3-8d58-e333145122ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lgo = LeaveOneGroupOut()\n",
    "clf = make_pipeline(CSP(n_components=8), LogisticRegression())\n",
    "\n",
    "y_pred = cross_val_predict(clf, X, y, groups=fnames, cv=lgo, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bbab71-bbe2-42de-911b-6dec030e59d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conf_mat = pd.DataFrame(\n",
    "    confusion_matrix(y, y_pred, labels=classes),\n",
    "    columns=pd.Index(classes, name=\"PREDICTED\"),\n",
    "    index=pd.Index(classes, name=\"TRUE\"),\n",
    ")\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03de304-09f5-41c1-9532-086ad0c4e2d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bci-BKI323",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
