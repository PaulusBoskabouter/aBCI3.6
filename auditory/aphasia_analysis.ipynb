{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e8517e8",
   "metadata": {},
   "source": [
    "# Aphasia BCI Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50dda7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from pathlib import Path\n",
    "import mne\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GroupKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e0262df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "def load_session(data_root: Path, prefix: str = 'AuditoryAphasia') -> mne.io.BaseRaw:\n",
    "    \"\"\" Load BrainVision EEG data to mne.io.BaseRaw object \"\"\"\n",
    "    \n",
    "    # Get all header files\n",
    "    hdr_files = list(data_root.rglob(f'{prefix}*.vhdr'))\n",
    "    hdr_files.sort()\n",
    "\n",
    "    # read into single raw\n",
    "    raws = [mne.io.read_raw_brainvision(hdrf) for hdrf in hdr_files]\n",
    "    \n",
    "    return mne.concatenate_raws(raws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d71dd132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from sub-VPpdfc/ses-230221/AuditoryAphasia_pre_6d_250_0001.vhdr...\n",
      "Setting channel info structure...\n",
      "Extracting parameters from sub-VPpdfc/ses-230221/AuditoryAphasia_pre_6d_250_0002.vhdr...\n",
      "Setting channel info structure...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>February 23, 2023  11:07:12 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>Not available</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>32 EEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>500.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.02 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>1000.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "</table>"
      ],
      "text/plain": [
       "<Info | 7 non-empty values\n",
       " bads: []\n",
       " ch_names: Fp2, F4, F8, FC6, C4, T8, CP2, CP6, TP10, P8, O2, PO10, P4, Cz, ...\n",
       " chs: 32 EEG\n",
       " custom_ref_applied: False\n",
       " highpass: 0.0 Hz\n",
       " lowpass: 1000.0 Hz\n",
       " meas_date: 2023-02-23 11:07:12 UTC\n",
       " nchan: 32\n",
       " projs: []\n",
       " sfreq: 500.0 Hz\n",
       ">"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_root = Path('./sub-VPpdfc/ses-230221/')\n",
    "raws = load_session(data_root)\n",
    "raws.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a3cf39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raws to epochs\n",
    "# --------------------------------------------------------------------------\n",
    "# from the aphasia repo, we know\n",
    "# markers['target'] = [111,112,113,114,115,116]\n",
    "# markers['nontarget'] = [101,102,103,104,105,106]\n",
    "# markers['new-trial'] = [200,201,202,203,204,205]\n",
    "markers = {'target': [111,112,113,114,115,116], 'nontarget': [101,102,103,104,105,106]}\n",
    "\n",
    "def raws_to_epochs(raws: mne.io.BaseRaw, markers: dict = markers) -> mne.Epochs:\n",
    "    ev, evid = mne.events_from_annotations(raws, verbose=False)\n",
    "\n",
    "    # select the start events only\n",
    "    sev = ev[np.isin(ev[:, 2], markers['target'] + markers['nontarget'])]\n",
    "\n",
    "    # use mne's naming convention to be able to select targets and nontargets more easily\n",
    "    names = {f'{k}/{e}': e for k, v in markers.items() for e in v}\n",
    "\n",
    "    epo = mne.Epochs(raws, sev, event_id=names, tmin=-.2, tmax=1.2, verbose=False)\n",
    "    \n",
    "    return epo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8a63d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 1080 events and 701 original time points ...\n",
      "0 bad epochs dropped\n",
      "Loading data for 1080 events and 701 original time points ...\n",
      "Setting up band-pass filter from 0.5 - 8 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 8.00 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 9.00 Hz)\n",
      "- Filter length: 3301 samples (6.602 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lq/l9pj97fx0xvc336klq1wkth40000gp/T/ipykernel_17989/3611833739.py:12: RuntimeWarning: filter_length (3301) is longer than the signal (701), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  epo.filter(0.5, 8)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 34560 out of 34560 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        \n",
       "        <td>nontarget/101: 150<br/>nontarget/102: 150<br/>nontarget/103: 150<br/>nontarget/104: 150<br/>nontarget/105: 150<br/>nontarget/106: 150<br/>target/111: 30<br/>target/112: 30<br/>target/113: 30<br/>target/114: 30<br/>target/115: 30<br/>target/116: 30</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>-0.200 – 1.200 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>-0.200 – 0.000 sec</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Epochs |  1080 events (all good), -0.2 - 1.2 sec, baseline -0.2 – 0 sec, ~184.9 MB, data loaded,\n",
       " 'target/111': 30\n",
       " 'target/112': 30\n",
       " 'target/113': 30\n",
       " 'target/114': 30\n",
       " 'target/115': 30\n",
       " 'target/116': 30\n",
       " 'nontarget/101': 150\n",
       " 'nontarget/102': 150\n",
       " 'nontarget/103': 150\n",
       " 'nontarget/104': 150\n",
       " and 2 more events ...>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing\n",
    "epo = raws_to_epochs(raws)\n",
    "\n",
    "# load data\n",
    "epo.drop_bad()\n",
    "epo.load_data()\n",
    "\n",
    "# set montage\n",
    "epo.set_montage(\"standard_1020\")\n",
    "\n",
    "# frequency filtering\n",
    "epo.filter(0.5, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78ae41af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create spatio temporal features from the epochs\n",
    "\n",
    "# Note these are the default time windows we use in the Aphasia protocol, feel free to experiment\n",
    "# with a different window set and see if you find a more optimal choice\n",
    "twin = [[0.08, 0.15],\n",
    "        [0.151, 0.21],\n",
    "        [0.211, 0.28],\n",
    "        [0.271, 0.35],\n",
    "        [0.351, 0.44],\n",
    "        [0.45, 0.56],\n",
    "        [0.561, 0.7],\n",
    "        [0.701, 0.85],\n",
    "        [0.851, 1],\n",
    "        [1.001, 1.2]]\n",
    "\n",
    "# default channels set - also feel free to experiment with different channel sets\n",
    "channels = ['Fp2', 'F4', 'F8', 'FC6', 'C4', 'T8', 'CP2', 'CP6', 'TP10', 'P8', 'O2', 'PO10',\n",
    "            'P4', 'Cz', 'Pz', 'Oz', 'PO9', 'O1', 'P7', 'P3', 'CP5', 'CP1', 'T7', 'C3', 'FC1',\n",
    "            'FCz', 'FC2', 'Fz', 'FC5', 'F7', 'F3', 'Fp1']\n",
    "\n",
    "def epochs_to_features(epo: mne.BaseEpochs,\n",
    "                       twin: list[list[float]] = twin,\n",
    "                       channels: list[str] = channels,\n",
    "                      ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Take the epochs object with data in shape (n_epochs, n_channels, n_times) and calculate \n",
    "    spatio temporal features for each epoch into a data matrix (n_epochs, n_features)\n",
    "    \"\"\"\n",
    "\n",
    "    X = []\n",
    "    n_epochs = len(epo)\n",
    "    for tw in twin:\n",
    "        X.append(\n",
    "            epo.copy()\n",
    "            .crop(*tw)\n",
    "            .pick(channels)\n",
    "            .get_data()\n",
    "            .mean(axis=-1)   # mean accross time window\n",
    "            .reshape(n_epochs, -1))\n",
    "    X = np.hstack(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b8f58b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate features and extract labels\n",
    "X = epochs_to_features(epo)\n",
    "y = np.asarray(\n",
    "    [0 if e[-1] in markers['nontarget'] else 1 for e in epo.events]  # 0 for nontarget, 1 for target\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835a0d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3daec5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a classifier\n",
    "clf = make_pipeline(\n",
    "        LDA(solver='eigen', shrinkage='auto'),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "14cd4977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy in 80/20 split: acc=0.8425925925925926\n"
     ]
    }
   ],
   "source": [
    "# test on a simple 80 / 20 split\n",
    "ix = np.arange(len(y))\n",
    "cutoff = int(.8 * len(ix))\n",
    "ixtrain, ixtest = ix[:cutoff], ix[cutoff:]\n",
    "\n",
    "clf.fit(X[ixtrain], y[ixtrain])\n",
    "ypred = clf.predict(X[ixtest])\n",
    "\n",
    "acc = accuracy_score(y[ixtest], ypred)\n",
    "print(f\"Accuracy in 80/20 split: {acc=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "adb71c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing n=10 splits during cross validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validation score: 0.837037037037037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    5.5s finished\n"
     ]
    }
   ],
   "source": [
    "# do a more proper cross validation\n",
    "# from the way the paradigm was created, we know that we have 6 words which include one target word\n",
    "# so a grouping in blocks of 6 words seems a natural way\n",
    "\n",
    "assert len(epo) % 6 == 0, \"The number of epochs is not a multiple of 6.\"\\\n",
    "\" The data seems to include incomplete repetitions. Check which epochs belong to an incomplete block.\"\n",
    "\n",
    "groups = np.arange(len(epo) // 6).repeat(6)\n",
    "\n",
    "# check that there is exactly one target in each group\n",
    "assert all([y[groups == g].sum() == 1 for g in np.unique(groups)]), \"There are groups which do not have exactly\"\\\n",
    "\" one target epoch in them. Please investigate.\"\n",
    "cv = GroupKFold(10)\n",
    "print(f\"Processing n={len(list(cv.split(X, y, groups=groups)))} splits during cross validation.\")\n",
    "\n",
    "scores = cross_val_score(clf, X, y, groups=groups, cv=cv, verbose=True)\n",
    "\n",
    "print(f\"Mean cross validation score: {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b8ef9733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.model_selection._split.GroupKFold"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3b12d027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>PREDICTED</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRUE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>863</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>139</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "PREDICTED    0   1\n",
       "TRUE              \n",
       "0          863  37\n",
       "1          139  41"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the confusion matrix to get a better understanding of how the classifier works\n",
    "y_pred = cross_val_predict(clf, X, y, groups=groups, cv=cv, verbose=False)\n",
    "classes = [0, 1]\n",
    "conf_mat = pd.DataFrame(\n",
    "    confusion_matrix(y, y_pred, labels=classes), \n",
    "    columns=pd.Index(classes, name='PREDICTED'), \n",
    "    index=pd.Index(classes, name='TRUE'),\n",
    ")\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d6c0e81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = list(cv.split(X, y, groups=groups))\n",
    "ixtrain, ixtest = splits[0]\n",
    "\n",
    "clf.fit(X[ixtrain], y[ixtrain])\n",
    "ydesc = clf.decision_function(X[ixtest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a55f186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we see above, the confusion matrix reveals a problem of the classifier: We have quite a lot\n",
    "# of false negatives. Lets see how our performance would be, if we where to classify at least one \n",
    "# tagert per group (whe have this information in the from the aphasia paper)\n",
    "\n",
    "def aphasia_cross_val(clf: Pipeline, X: np.ndarray, y: np.ndarray, groups: np.ndarray,\n",
    "                      cv: GroupKFold) -> list[float]:\n",
    "    \"\"\" Perform a cross validation in which we enforce to decode on target per group \"\"\"\n",
    "    \n",
    "    scores = []\n",
    "    preds = np.zeros(len(y))  # store the prediction values from each fold to compute a confusion\n",
    "                              # matrix later\n",
    "    \n",
    "    for ixtrain, ixtest in cv.split(X, y, groups):\n",
    "        fold_clf = deepcopy(clf)\n",
    "        fold_clf.fit(X[ixtrain], y[ixtrain])\n",
    "        \n",
    "        ypred = np.zeros(len(ixtest))\n",
    "        # loop over the group indeces in the test epochs (each group is a tuple of 6 epochs)\n",
    "        for g in np.unique(groups[ixtest]):\n",
    "            gmask = groups[ixtest] == g\n",
    "            decf = fold_clf.decision_function(X[ixtest][gmask])\n",
    "            \n",
    "            # choose only the position where the decision function is max. In case of a tie choose al\n",
    "            ix = np.arange(len(ypred))[gmask][decf == decf.max()]\n",
    "            ypred[ix] = 1\n",
    "        \n",
    "        # Calculate the accuracy of the predictions\n",
    "        scores.append(accuracy_score(y[ixtest], ypred))\n",
    "        preds[ixtest] = ypred\n",
    "\n",
    "    return scores, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "fb60ac92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross validation score: 0.8148148148148149\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>PREDICTED</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRUE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "PREDICTED    0    1\n",
       "TRUE               \n",
       "0          800  100\n",
       "1          100   80"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores, preds = aphasia_cross_val(clf, X, y, groups=groups, cv=cv)\n",
    "\n",
    "print(f\"Mean cross validation score: {np.mean(scores)}\")\n",
    "\n",
    "classes = [0, 1]\n",
    "conf_mat = pd.DataFrame(\n",
    "    confusion_matrix(y, preds, labels=classes), \n",
    "    columns=pd.Index(classes, name='PREDICTED'), \n",
    "    index=pd.Index(classes, name='TRUE'),\n",
    ")\n",
    "conf_mat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
